{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.8"
    },
    "colab": {
      "name": "Textclassification_with_XLNET.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/cece666/Cloud-Database/blob/master/Textclassification_with_XLNET.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RTqvmDeKftzm",
        "colab_type": "text"
      },
      "source": [
        "# Give access to google drive"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yz8IYrSsfyuA",
        "colab_type": "code",
        "outputId": "656fd887-5cb2-4173-aab0-dcbbab5c3f49",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        }
      },
      "source": [
        "!apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "!add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "!apt-get update -qq 2>&1 > /dev/null\n",
        "!apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "!google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "!echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "E: Package 'python-software-properties' has no installation candidate\n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 131289 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.6-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.6-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.6-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "··········\n",
            "Please, open the following URL in a web browser: https://accounts.google.com/o/oauth2/auth?client_id=32555940559.apps.googleusercontent.com&redirect_uri=urn%3Aietf%3Awg%3Aoauth%3A2.0%3Aoob&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force\n",
            "Please enter the verification code: Access token retrieved correctly.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DaUyvR6cgFik",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!mkdir -p drive\n",
        "!google-drive-ocamlfuse drive"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eIpToqRQgItk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "os.chdir(\"drive/Colab Notebooks/XLNet_test_classification\") "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pfjXpELmgRy-",
        "colab_type": "code",
        "outputId": "130c9ed7-61aa-4f84-dced-ad8faec08e4a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "!ls"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "data  NLP_In_Action.zip.tmp  README.md\tTextclassification_with_XLNET.ipynb\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YD0TjSeggTHp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JsywHiJwgTtt",
        "colab_type": "text"
      },
      "source": [
        "# Import library"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mVB5Qc_4lZPc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%reload_ext autoreload\n",
        "%autoreload 2\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jabf4ESKlZPw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import math\n",
        "import numpy as np\n",
        "from sklearn.metrics import classification_report\n",
        "import torch.nn.functional as F"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBkp56M2lZP8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import os\n",
        "from tqdm import tqdm,trange\n",
        "from torch.optim import Adam\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from sklearn.model_selection import train_test_split\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RxFVYHBFgq2U",
        "colab_type": "code",
        "outputId": "20785de1-6a25-4b7a-8106-99dd31ebcb8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 541
        }
      },
      "source": [
        "!pip install pytorch_pretrained_bert"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_pretrained_bert\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/e0/c08d5553b89973d9a240605b9c12404bcf8227590de62bae27acbcfe076b/pytorch_pretrained_bert-0.6.2-py3-none-any.whl (123kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.9.205)\n",
            "Requirement already satisfied: torch>=0.4.1 in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.1.0)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (4.28.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (2.21.0)\n",
            "Collecting regex (from pytorch_pretrained_bert)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/6f/4e/1b178c38c9a1a184288f72065a65ca01f3154df43c6ad898624149b8b4e0/regex-2019.06.08.tar.gz (651kB)\n",
            "\u001b[K     |████████████████████████████████| 655kB 8.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_pretrained_bert) (1.16.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.2.1)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.205 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (1.12.205)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_pretrained_bert) (0.9.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2.8)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (2019.6.16)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_pretrained_bert) (3.0.4)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.205->boto3->pytorch_pretrained_bert) (2.5.3)\n",
            "Requirement already satisfied: docutils<0.15,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.205->boto3->pytorch_pretrained_bert) (0.14)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.205->boto3->pytorch_pretrained_bert) (1.12.0)\n",
            "Building wheels for collected packages: regex\n",
            "  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for regex: filename=regex-2019.6.8-cp36-cp36m-linux_x86_64.whl size=604154 sha256=293b1c6faee054dcd714d79ba165396ce97220491395408f7e47d93c704c98fb\n",
            "  Stored in directory: /root/.cache/pip/wheels/35/e4/80/abf3b33ba89cf65cd262af8a22a5a999cc28fbfabea6b38473\n",
            "Successfully built regex\n",
            "Installing collected packages: regex, pytorch-pretrained-bert\n",
            "Successfully installed pytorch-pretrained-bert-0.6.2 regex-2019.6.8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QUNVzdQJlZQI",
        "colab_type": "code",
        "outputId": "b0fb8f50-a54f-4e06-fbf2-d27a15497257",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 469
        }
      },
      "source": [
        "!pip install pytorch_transformers"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pytorch_transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/89/ad0d6bb932d0a51793eaabcf1617a36ff530dc9ab9e38f765a35dc293306/pytorch_transformers-1.1.0-py3-none-any.whl (158kB)\n",
            "\u001b[K     |████████████████████████████████| 163kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.16.4)\n",
            "Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.1.0)\n",
            "Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (2019.6.8)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (2.21.0)\n",
            "Requirement already satisfied: boto3 in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (1.9.205)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from pytorch_transformers) (4.28.1)\n",
            "Collecting sentencepiece (from pytorch_transformers)\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/3d/efb655a670b98f62ec32d66954e1109f403db4d937c50d779a75b9763a29/sentencepiece-0.1.83-cp36-cp36m-manylinux1_x86_64.whl (1.0MB)\n",
            "\u001b[K     |████████████████████████████████| 1.0MB 36.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (2019.6.16)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->pytorch_transformers) (3.0.4)\n",
            "Requirement already satisfied: botocore<1.13.0,>=1.12.205 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (1.12.205)\n",
            "Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (0.9.4)\n",
            "Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from boto3->pytorch_transformers) (0.2.1)\n",
            "Requirement already satisfied: docutils<0.15,>=0.10 in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.205->boto3->pytorch_transformers) (0.14)\n",
            "Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.6/dist-packages (from botocore<1.13.0,>=1.12.205->boto3->pytorch_transformers) (2.5.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\"->botocore<1.13.0,>=1.12.205->boto3->pytorch_transformers) (1.12.0)\n",
            "Installing collected packages: sentencepiece, pytorch-transformers\n",
            "Successfully installed pytorch-transformers-1.1.0 sentencepiece-0.1.83\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iGN_eMZulZQV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pytorch_transformers import (XLNetConfig, XLNetForSequenceClassification, XLNetTokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdBxBMlxlZRO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v226sa9XlZRd",
        "colab_type": "text"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wbSNYEgylZRh",
        "colab_type": "text"
      },
      "source": [
        "**Load CSV data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RESiBpZElZRm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_path = \"data/\" "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2F2Ri6oPlZR-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "data_file_address = \"data/review1star5star_dataset\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_gC6bmOklZSS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_data = pd.read_csv(data_file_address,sep=\",\",encoding=\"utf-8\",names=['labels','texts'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUJtiEcLlZSn",
        "colab_type": "code",
        "outputId": "973b67b2-a7b5-469a-ebb7-398c42aa6dd2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df_data.columns"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['labels', 'texts'], dtype='object')"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OXbxAqt362mI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_data.iloc[0]=df_data.iloc[5]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N7NWgZ8zlZS2",
        "colab_type": "code",
        "outputId": "60de878e-c487-4530-9446-42938849fc53",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 662
        }
      },
      "source": [
        "df_data.head(n=20)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>labels</th>\n",
              "      <th>texts</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>spagetti had little sauce penne had only diced...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>kim and raju was so awesome</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>one of the few places that i can take my picky...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>it was fabulous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>it's off the beaten path not on the strip but ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>0</td>\n",
              "      <td>spagetti had little sauce penne had only diced...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>1</td>\n",
              "      <td>he was kind and extremely quick to do things w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1</td>\n",
              "      <td>i will now be a frequent flyer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>0</td>\n",
              "      <td>went because of a groupon offer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>0</td>\n",
              "      <td>this place has really cheap prices and it's be...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>0</td>\n",
              "      <td>it's been close to 30 minutes and the 8 at our...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>1</td>\n",
              "      <td>by comparison the south outlet trust me i go t...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>1</td>\n",
              "      <td>fish were very fresh and for this week they ar...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>1</td>\n",
              "      <td>legit one of my fav spots to eat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>1</td>\n",
              "      <td>yummy yummy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>0</td>\n",
              "      <td>what type of restaurant employee calls their c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>1</td>\n",
              "      <td>flavor is just right noodles are not soft but ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>1</td>\n",
              "      <td>he answered our many questions has excellent w...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>0</td>\n",
              "      <td>seems like this has been a recurring problem a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>1</td>\n",
              "      <td>i had a great experience here joined a friend ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   labels                                              texts\n",
              "0       0  spagetti had little sauce penne had only diced...\n",
              "1       1                        kim and raju was so awesome\n",
              "2       1  one of the few places that i can take my picky...\n",
              "3       1                                    it was fabulous\n",
              "4       1  it's off the beaten path not on the strip but ...\n",
              "5       0  spagetti had little sauce penne had only diced...\n",
              "6       1  he was kind and extremely quick to do things w...\n",
              "7       1                     i will now be a frequent flyer\n",
              "8       0                    went because of a groupon offer\n",
              "9       0  this place has really cheap prices and it's be...\n",
              "10      0  it's been close to 30 minutes and the 8 at our...\n",
              "11      1  by comparison the south outlet trust me i go t...\n",
              "12      1  fish were very fresh and for this week they ar...\n",
              "13      1                   legit one of my fav spots to eat\n",
              "14      1                                        yummy yummy\n",
              "15      0  what type of restaurant employee calls their c...\n",
              "16      1  flavor is just right noodles are not soft but ...\n",
              "17      1  he answered our many questions has excellent w...\n",
              "18      0  seems like this has been a recurring problem a...\n",
              "19      1  i had a great experience here joined a friend ..."
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhY_XUOOlZS_",
        "colab_type": "text"
      },
      "source": [
        "**Have a look labels**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-NMjJJ2lZTC",
        "colab_type": "code",
        "outputId": "06cffac4-ea8f-4c18-bb5a-79162fd33f60",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df_data['labels'].unique()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array(['0', '1'], dtype=object)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ay2a9PQxlZTO",
        "colab_type": "code",
        "outputId": "06844eb8-b545-4af5-c4fc-7eb1ea908d6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "# Analyse the labels distribution\n",
        "df_data['labels'].value_counts()"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1999\n",
              "0    1000\n",
              "Name: labels, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h2PKsZWnlZTX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSSqhHR8lZTg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3bQzy3_HlZTn",
        "colab_type": "text"
      },
      "source": [
        "## Parser data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JXDSU5P3lZTq",
        "colab_type": "text"
      },
      "source": [
        "**Parser data into document structure**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oIlbYrWdlZTt",
        "colab_type": "code",
        "outputId": "6694ff05-6563-4170-fa1f-ba1e6a4369a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Get sentence data\n",
        "sentences = df_data['texts']\n",
        "sentences[0]"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'spagetti had little sauce penne had only diced tomatoes as a sauce and came out 1 2 cold'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rU9xu4LHlZT3",
        "colab_type": "code",
        "outputId": "6b4f7e08-10bb-4b91-d639-6cfacf1469a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Get tag labels data\n",
        "labels = df_data['labels']\n",
        "print(labels[0])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lv87y4RQlZUF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WAGrtoURlZUQ",
        "colab_type": "text"
      },
      "source": [
        "**Make TAG name into index for training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G7nnQZg-lZUS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# 0:negative, 1: positive\n",
        "tag2idx={'0': 0,\n",
        " '1': 1}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jcTYmUBklZUX",
        "colab_type": "code",
        "outputId": "01774913-151f-49c3-857f-77e3ad7ba0db",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tag2idx"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0': 0, '1': 1}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KzMlnGcDlZUe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Mapping index to name\n",
        "tag2name={tag2idx[key] : key for key in tag2idx.keys()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WOwVN43NlZUm",
        "colab_type": "code",
        "outputId": "e66d6818-3e6a-42d8-99ce-8c63afd1d2a5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tag2name"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: '0', 1: '1'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "30Cj5Zn-lZUs",
        "colab_type": "text"
      },
      "source": [
        "## Make tranning data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lxqSt8yMlZU2",
        "colab_type": "text"
      },
      "source": [
        "**Set up gpu environment**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jw3s1XZ0lZU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "n_gpu = torch.cuda.device_count()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KjU3URd-lZU9",
        "colab_type": "code",
        "outputId": "b5433e7b-0696-46ed-b3be-cd867b5adba5",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "n_gpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9plR7LylZVD",
        "colab_type": "text"
      },
      "source": [
        "### Load tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sS6JHyaNlZVI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocabulary = 'data/xlnet-base-cased/xlnet-base-cased-spiece.model'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Si4s-u_xlZVQ",
        "colab_type": "code",
        "outputId": "11c35c0b-9822-4088-bb09-cd0862504630",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "vocabulary"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'data/xlnet-base-cased/xlnet-base-cased-spiece.model'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m3SVRmnblZVW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "max_len  = 64"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKRVTceOlZVb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tokenizer = XLNetTokenizer(vocab_file=vocabulary,do_lower_case=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "537Qmpj-lZVg",
        "colab_type": "code",
        "outputId": "94f62c96-9637-41e8-9ef5-73236e1bc628",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "tokenizer"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<pytorch_transformers.tokenization_xlnet.XLNetTokenizer at 0x7f1656420eb8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bsgd154ylZVm",
        "colab_type": "text"
      },
      "source": [
        "### Set text input embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EAKimEWylZVp",
        "colab_type": "text"
      },
      "source": [
        "- token id embedding\n",
        "- mask embedding\n",
        "- segment embedding"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h9RuaVrplZV_",
        "colab_type": "text"
      },
      "source": [
        "**This process is huge differnent from BERT**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u0USwJWclZWB",
        "colab_type": "code",
        "outputId": "5ee5b307-b520-4cc1-826b-fa8d75b75bac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        }
      },
      "source": [
        "max_len  = 64\n",
        "\n",
        "full_input_ids = []\n",
        "full_input_masks = []\n",
        "full_segment_ids = []\n",
        "\n",
        "SEG_ID_A   = 0\n",
        "SEG_ID_B   = 1\n",
        "SEG_ID_CLS = 2\n",
        "SEG_ID_SEP = 3\n",
        "SEG_ID_PAD = 4\n",
        "\n",
        "UNK_ID = tokenizer.encode(\"<unk>\")[0]\n",
        "CLS_ID = tokenizer.encode(\"<cls>\")[0]\n",
        "SEP_ID = tokenizer.encode(\"<sep>\")[0]\n",
        "MASK_ID = tokenizer.encode(\"<mask>\")[0]\n",
        "EOD_ID = tokenizer.encode(\"<eod>\")[0]\n",
        "\n",
        "for i,sentence in enumerate(sentences):\n",
        "    # Tokenize sentence to token id list\n",
        "    tokens_a = tokenizer.encode(sentence)\n",
        "    \n",
        "    # Trim the len of text\n",
        "    if(len(tokens_a)>max_len-2):\n",
        "        tokens_a = tokens_a[:max_len-2]\n",
        "        \n",
        "        \n",
        "    tokens = []\n",
        "    segment_ids = []\n",
        "    \n",
        "    for token in tokens_a:\n",
        "        tokens.append(token)\n",
        "        segment_ids.append(SEG_ID_A)\n",
        "        \n",
        "    # Add <sep> token \n",
        "    tokens.append(SEP_ID)\n",
        "    segment_ids.append(SEG_ID_A)\n",
        "    \n",
        "    \n",
        "    # Add <cls> token\n",
        "    tokens.append(CLS_ID)\n",
        "    segment_ids.append(SEG_ID_CLS)\n",
        "    \n",
        "    input_ids = tokens\n",
        "    \n",
        "    # The mask has 0 for real tokens and 1 for padding tokens. Only real\n",
        "    # tokens are attended to.\n",
        "    input_mask = [0] * len(input_ids)\n",
        "\n",
        "    # Zero-pad up to the sequence length at fornt\n",
        "    if len(input_ids) < max_len:\n",
        "        delta_len = max_len - len(input_ids)\n",
        "        input_ids = [0] * delta_len + input_ids\n",
        "        input_mask = [1] * delta_len + input_mask\n",
        "        segment_ids = [SEG_ID_PAD] * delta_len + segment_ids\n",
        "\n",
        "    assert len(input_ids) == max_len\n",
        "    assert len(input_mask) == max_len\n",
        "    assert len(segment_ids) == max_len\n",
        "    \n",
        "    full_input_ids.append(input_ids)\n",
        "    full_input_masks.append(input_mask)\n",
        "    full_segment_ids.append(segment_ids)\n",
        "    \n",
        "    if 3 > i:\n",
        "        print(\"No.:%d\"%(i))\n",
        "        print(\"sentence: %s\"%(sentence))\n",
        "        print(\"input_ids:%s\"%(input_ids))\n",
        "        print(\"attention_masks:%s\"%(input_mask))\n",
        "        print(\"segment_ids:%s\"%(segment_ids))\n",
        "        print(\"\\n\")\n",
        "    \n",
        "    \n",
        "    \n",
        "    "
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "No.:0\n",
            "sentence: spagetti had little sauce penne had only diced tomatoes as a sauce and came out 1 2 cold\n",
            "input_ids:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 23, 5130, 6170, 54, 293, 7633, 6995, 667, 54, 114, 17, 5958, 68, 15592, 34, 24, 7633, 21, 301, 78, 156, 159, 1946, 4, 3]\n",
            "attention_masks:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "segment_ids:[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "\n",
            "\n",
            "No.:1\n",
            "sentence: kim and raju was so awesome\n",
            "input_ids:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17, 2548, 98, 21, 17, 840, 2795, 30, 102, 8729, 4, 3]\n",
            "attention_masks:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "segment_ids:[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "\n",
            "\n",
            "No.:2\n",
            "sentence: one of the few places that i can take my picky teens two and both love the food\n",
            "input_ids:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 65, 20, 18, 274, 1920, 29, 17, 150, 64, 182, 94, 1947, 117, 11411, 87, 21, 207, 564, 18, 626, 4, 3]\n",
            "attention_masks:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
            "segment_ids:[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0H9Zf3l7lZWI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LSlgKRFXlZWQ",
        "colab_type": "text"
      },
      "source": [
        "### Set label embedding"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dc4d-wCslZWT",
        "colab_type": "code",
        "outputId": "5aa1e53d-1d94-4789-9374-49ef05e6fcb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "# Make label into id\n",
        "tags = [tag2idx[str(lab)] for lab in labels]\n",
        "print(tags)"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DLW2vvjvlZWg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7MpV_C3XlZWs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WbGhCxMalZWz",
        "colab_type": "text"
      },
      "source": [
        "## Split data into train and validate"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yldN22GPlZW3",
        "colab_type": "text"
      },
      "source": [
        "70% for training, 30% for validation"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZLYr36BulZW4",
        "colab_type": "text"
      },
      "source": [
        "**Split all data**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iy5svik6lZW6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_inputs, val_inputs, tr_tags, val_tags,tr_masks, val_masks,tr_segs, val_segs = train_test_split(full_input_ids, tags,full_input_masks,full_segment_ids, \n",
        "                                                            random_state=4, test_size=0.3)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tWi25E2FlZXP",
        "colab_type": "code",
        "outputId": "5ed71964-90e3-4d5a-c28c-17aacbc8ad71",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "len(tr_inputs),len(val_inputs),len(tr_segs),len(val_segs)"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2099, 900, 2099, 900)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RsbpuN9clZXW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A5ljKItHlZXl",
        "colab_type": "text"
      },
      "source": [
        "**Set data into tensor**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wO8JjYGKlZXn",
        "colab_type": "text"
      },
      "source": [
        "Not recommend tensor.to(device) at this process, since it will run out of GPU memory"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J36nYXAGlZXv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tr_inputs = torch.tensor(tr_inputs)\n",
        "val_inputs = torch.tensor(val_inputs)\n",
        "tr_tags = torch.tensor(tr_tags)\n",
        "val_tags = torch.tensor(val_tags)\n",
        "tr_masks = torch.tensor(tr_masks)\n",
        "val_masks = torch.tensor(val_masks)\n",
        "tr_segs = torch.tensor(tr_segs)\n",
        "val_segs = torch.tensor(val_segs)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l8GzujIElZX8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N3CqUqLOlZYJ",
        "colab_type": "text"
      },
      "source": [
        "**Put data into data loader**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lX28MGHblZYL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set batch num\n",
        "batch_num = 32"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MRx1ziHYlZYR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set token embedding, attention embedding, segment embedding\n",
        "train_data = TensorDataset(tr_inputs, tr_masks,tr_segs, tr_tags)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "# Drop last can make batch training better for the last one\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_num,drop_last=True)\n",
        "\n",
        "valid_data = TensorDataset(val_inputs, val_masks,val_segs, val_tags)\n",
        "valid_sampler = SequentialSampler(valid_data)\n",
        "valid_dataloader = DataLoader(valid_data, sampler=valid_sampler, batch_size=batch_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-ARWIKnlZYY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1f4594cb-3d0f-4fab-dfbd-7689ed3bc919"
      },
      "source": [
        "valid_dataloader"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.utils.data.dataloader.DataLoader at 0x7fd6501ac710>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F2Lk4GCUlZYe",
        "colab_type": "text"
      },
      "source": [
        "## Train model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bXEptItElZYf",
        "colab_type": "text"
      },
      "source": [
        "**Load XLNet model**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1xZ8s0ilZYg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_file_address = 'data/xlnet-base-cased'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3KS9ZfdulZYk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "model = XLNetForSequenceClassification.from_pretrained(model_file_address,num_labels=len(tag2idx))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qO2ugCdqlZYp",
        "colab_type": "code",
        "outputId": "be231b18-3b3a-4649-bf57-5c1fc9c94b26",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XLNetForSequenceClassification(\n",
              "  (transformer): XLNetModel(\n",
              "    (word_embedding): Embedding(32000, 768)\n",
              "    (layer): ModuleList(\n",
              "      (0): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): XLNetLayerNorm()\n",
              "          (dropout): Dropout(p=0.1)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): XLNetLayerNorm()\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1)\n",
              "      )\n",
              "      (1): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): XLNetLayerNorm()\n",
              "          (dropout): Dropout(p=0.1)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): XLNetLayerNorm()\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1)\n",
              "      )\n",
              "      (2): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): XLNetLayerNorm()\n",
              "          (dropout): Dropout(p=0.1)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): XLNetLayerNorm()\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1)\n",
              "      )\n",
              "      (3): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): XLNetLayerNorm()\n",
              "          (dropout): Dropout(p=0.1)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): XLNetLayerNorm()\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1)\n",
              "      )\n",
              "      (4): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): XLNetLayerNorm()\n",
              "          (dropout): Dropout(p=0.1)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): XLNetLayerNorm()\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1)\n",
              "      )\n",
              "      (5): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): XLNetLayerNorm()\n",
              "          (dropout): Dropout(p=0.1)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): XLNetLayerNorm()\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1)\n",
              "      )\n",
              "      (6): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): XLNetLayerNorm()\n",
              "          (dropout): Dropout(p=0.1)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): XLNetLayerNorm()\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1)\n",
              "      )\n",
              "      (7): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): XLNetLayerNorm()\n",
              "          (dropout): Dropout(p=0.1)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): XLNetLayerNorm()\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1)\n",
              "      )\n",
              "      (8): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): XLNetLayerNorm()\n",
              "          (dropout): Dropout(p=0.1)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): XLNetLayerNorm()\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1)\n",
              "      )\n",
              "      (9): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): XLNetLayerNorm()\n",
              "          (dropout): Dropout(p=0.1)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): XLNetLayerNorm()\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1)\n",
              "      )\n",
              "      (10): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): XLNetLayerNorm()\n",
              "          (dropout): Dropout(p=0.1)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): XLNetLayerNorm()\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1)\n",
              "      )\n",
              "      (11): XLNetLayer(\n",
              "        (rel_attn): XLNetRelativeAttention(\n",
              "          (layer_norm): XLNetLayerNorm()\n",
              "          (dropout): Dropout(p=0.1)\n",
              "        )\n",
              "        (ff): XLNetFeedForward(\n",
              "          (layer_norm): XLNetLayerNorm()\n",
              "          (layer_1): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (layer_2): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (dropout): Dropout(p=0.1)\n",
              "        )\n",
              "        (dropout): Dropout(p=0.1)\n",
              "      )\n",
              "    )\n",
              "    (dropout): Dropout(p=0.1)\n",
              "  )\n",
              "  (sequence_summary): SequenceSummary(\n",
              "    (summary): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "    (first_dropout): Identity()\n",
              "    (last_dropout): Dropout(p=0.1)\n",
              "  )\n",
              "  (logits_proj): Linear(in_features=768, out_features=2, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1WofvO8DlZYu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.to(device);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xcDNWScBHYBp",
        "colab_type": "code",
        "outputId": "7de5e19b-7024-44ea-9b43-4ad8af0dadb6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "n_gpu"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUogkJs-lZYz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if n_gpu >1:\n",
        "    model = torch.nn.DataParallel(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l_XnfYFplZZA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "epochs = 10\n",
        "max_grad_norm = 1.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3uaLhK-1lZZF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_train_optimization_steps = int( math.ceil(len(tr_inputs) / batch_num) / 1) * epochs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fKI74UmIlZZL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PoHjxEU5lZZS",
        "colab_type": "text"
      },
      "source": [
        "### Set fine tuning method"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A8n0nUnhlZZU",
        "colab_type": "text"
      },
      "source": [
        "**Manual optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kV4_H224lZZX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# True: fine tuning all the layers \n",
        "# False: only fine tuning the classifier layers\n",
        "FULL_FINETUNING = True"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6D6Gc-Q3lZZc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if FULL_FINETUNING:\n",
        "    # Fine tune model all layer parameters\n",
        "    param_optimizer = list(model.named_parameters())\n",
        "    no_decay = ['bias', 'gamma', 'beta']\n",
        "    optimizer_grouped_parameters = [\n",
        "        {'params': [p for n, p in param_optimizer if not any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.01},\n",
        "        {'params': [p for n, p in param_optimizer if any(nd in n for nd in no_decay)],\n",
        "         'weight_decay_rate': 0.0}\n",
        "    ]\n",
        "else:\n",
        "    # Only fine tune classifier parameters\n",
        "    param_optimizer = list(model.classifier.named_parameters()) \n",
        "    optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
        "optimizer = Adam(optimizer_grouped_parameters, lr=3e-5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fl4pNPBtlZZq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "optF-B0ylZZv",
        "colab_type": "text"
      },
      "source": [
        "### Fine-tuing model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z2pbXRZGlZZw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# TRAIN loop\n",
        "model.train();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "j2CTPKoAlZZ0",
        "colab_type": "code",
        "outputId": "b68cadcd-4ba4-4e00-d2b5-3f8197dfad5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        }
      },
      "source": [
        "print(\"***** Running training *****\")\n",
        "print(\"  Num examples = %d\"%(len(tr_inputs)))\n",
        "print(\"  Batch size = %d\"%(batch_num))\n",
        "print(\"  Num steps = %d\"%(num_train_optimization_steps))\n",
        "for _ in trange(epochs,desc=\"Epoch\"):\n",
        "    tr_loss = 0\n",
        "    nb_tr_examples, nb_tr_steps = 0, 0\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        # add batch to gpu\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_segs,b_labels = batch\n",
        "        \n",
        "        # forward pass\n",
        "        outputs = model(input_ids =b_input_ids,token_type_ids=b_segs, input_mask = b_input_mask,labels=b_labels)\n",
        "        loss, logits = outputs[:2]\n",
        "        if n_gpu>1:\n",
        "            # When multi gpu, average it\n",
        "            loss = loss.mean()\n",
        "        \n",
        "        # backward pass\n",
        "        loss.backward()\n",
        "        \n",
        "        # track train loss\n",
        "        tr_loss += loss.item()\n",
        "        nb_tr_examples += b_input_ids.size(0)\n",
        "        nb_tr_steps += 1\n",
        "        \n",
        "        # gradient clipping\n",
        "        torch.nn.utils.clip_grad_norm_(parameters=model.parameters(), max_norm=max_grad_norm)\n",
        "        \n",
        "        # update parameters\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "    # print train loss per epoch\n",
        "    print(\"Train loss: {}\".format(tr_loss/nb_tr_steps))\n",
        "        "
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:   0%|          | 0/10 [00:00<?, ?it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "***** Running training *****\n",
            "  Num examples = 2099\n",
            "  Batch size = 32\n",
            "  Num steps = 660\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  10%|█         | 1/10 [01:06<09:57, 66.34s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.5444673691804592\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  20%|██        | 2/10 [02:12<08:49, 66.23s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.35553334447053764\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  30%|███       | 3/10 [03:18<07:43, 66.18s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.26658834087160915\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  40%|████      | 4/10 [04:24<06:36, 66.12s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.1780720608165631\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  50%|█████     | 5/10 [05:30<05:30, 66.08s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.11666786848352506\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  60%|██████    | 6/10 [06:36<04:24, 66.04s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.09507784076894706\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  70%|███████   | 7/10 [07:42<03:17, 66.00s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.0723769629947268\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  80%|████████  | 8/10 [08:48<02:11, 66.00s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.0932028115225526\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch:  90%|█████████ | 9/10 [09:54<01:05, 65.97s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.05010815122379707\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\rEpoch: 100%|██████████| 10/10 [10:59<00:00, 65.93s/it]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.08071058776516181\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2OpNRnJnlZaP",
        "colab_type": "text"
      },
      "source": [
        "## Save model "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KWX6pmpClZaQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "xlnet_out_address = 'data/xlnet_out_model/review_model'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f7rYhcy_lZaY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Make dir if not exits\n",
        "if not os.path.exists(xlnet_out_address):\n",
        "        os.makedirs(xlnet_out_address)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i7tRQIGIlZao",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Save a trained model, configuration and tokenizer\n",
        "model_to_save = model.module if hasattr(model, 'module') else model  # Only save the model it-self"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IAJIp4FlZa2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# If we save using the predefined names, we can load using `from_pretrained`\n",
        "output_model_file = os.path.join(xlnet_out_address, \"pytorch_model.bin\")\n",
        "output_config_file = os.path.join(xlnet_out_address, \"config.json\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "TfXPH3jVlZbB",
        "colab_type": "code",
        "outputId": "c2562d8d-0227-4e72-b4fb-4f68e0d38165",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Save model into file\n",
        "torch.save(model_to_save.state_dict(), output_model_file)\n",
        "model_to_save.config.to_json_file(output_config_file)\n",
        "tokenizer.save_vocabulary(xlnet_out_address)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "('data/xlnet_out_model/review_model/spiece.model',)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPr0R3OxlZbI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VlpZk3rXlZbP",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VbMEaXpWlZbY",
        "colab_type": "text"
      },
      "source": [
        "## Load model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-Au8H89olZbZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = XLNetForSequenceClassification.from_pretrained(xlnet_out_address,num_labels=len(tag2idx))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7nsz-5rclZbh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set model to GPU\n",
        "model.to(device);"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RWMAPyQ5lZbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "if n_gpu >1:\n",
        "    model = torch.nn.DataParallel(model)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q9bCmL6zlZbt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5FnOb0hzlZby",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xC-w4nJXlZb2",
        "colab_type": "text"
      },
      "source": [
        "## Eval model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fkgokJKolZb4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Evalue loop\n",
        "model.eval();"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOdmBW4JlZcH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Set acc funtion\n",
        "def accuracy(out, labels):\n",
        "    outputs = np.argmax(out, axis=1)\n",
        "    return np.sum(outputs == labels)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7zQ13oD-lZcV",
        "colab_type": "code",
        "outputId": "2ef15374-0ae8-48b2-85cd-20d3418a79f3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        }
      },
      "source": [
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "y_true = []\n",
        "y_predict = []\n",
        "print(\"***** Running evaluation *****\")\n",
        "print(\"  Num examples ={}\".format(len(val_inputs)))\n",
        "print(\"  Batch size = {}\".format(batch_num))\n",
        "for step, batch in enumerate(valid_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_segs,b_labels = batch\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        outputs = model(input_ids =b_input_ids,token_type_ids=b_segs, input_mask = b_input_mask,labels=b_labels)\n",
        "        tmp_eval_loss, logits = outputs[:2]\n",
        "    \n",
        "    # Get textclassification predict result\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    tmp_eval_accuracy = accuracy(logits, label_ids)\n",
        "#     print(tmp_eval_accuracy)\n",
        "#     print(np.argmax(logits, axis=1))\n",
        "#     print(label_ids)\n",
        "    \n",
        "    # Save predict and real label reuslt for analyze\n",
        "    for predict in np.argmax(logits, axis=1):\n",
        "        y_predict.append(predict)\n",
        "        \n",
        "    for real_result in label_ids.tolist():\n",
        "        y_true.append(real_result)\n",
        "\n",
        "    \n",
        "    eval_loss += tmp_eval_loss.mean().item()\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "   \n",
        "    nb_eval_steps += 1\n",
        "    \n",
        "    \n",
        "eval_loss = eval_loss / nb_eval_steps\n",
        "eval_accuracy = eval_accuracy / len(val_inputs)\n",
        "loss = tr_loss/nb_tr_steps \n",
        "result = {'eval_loss': eval_loss,\n",
        "                  'eval_accuracy': eval_accuracy,\n",
        "                  'loss': loss}\n",
        "report = classification_report(y_pred=np.array(y_predict),y_true=np.array(y_true))\n",
        "\n",
        "# Save the report into file\n",
        "output_eval_file = os.path.join(xlnet_out_address, \"eval_results.txt\")\n",
        "with open(output_eval_file, \"w\") as writer:\n",
        "    print(\"***** Eval results *****\")\n",
        "    for key in sorted(result.keys()):\n",
        "        print(\"  %s = %s\"%(key, str(result[key])))\n",
        "        writer.write(\"%s = %s\\n\" % (key, str(result[key])))\n",
        "        \n",
        "    print(report)\n",
        "    writer.write(\"\\n\\n\")  \n",
        "    writer.write(report)"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "***** Running evaluation *****\n",
            "  Num examples =900\n",
            "  Batch size = 32\n",
            "***** Eval results *****\n",
            "  eval_accuracy = 0.8355555555555556\n",
            "  eval_loss = 0.8740155285802381\n",
            "  loss = 0.08071058776516181\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.65      0.72       298\n",
            "           1       0.84      0.93      0.88       602\n",
            "\n",
            "    accuracy                           0.84       900\n",
            "   macro avg       0.83      0.79      0.80       900\n",
            "weighted avg       0.83      0.84      0.83       900\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZRyjKszHlZcb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BKbsKiF_vFa7",
        "colab_type": "text"
      },
      "source": [
        "**classification**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8jD2yOt4lZcf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def encodeSentence(sentence,tag):\n",
        "  \n",
        "    tag=tag\n",
        "   # Tokenize sentence to token id list\n",
        "    tokens_a = tokenizer.encode(sentence)\n",
        "    \n",
        "    # Trim the len of text\n",
        "    if(len(tokens_a)>max_len-2):\n",
        "        tokens_a = tokens_a[:max_len-2]\n",
        "        \n",
        "        \n",
        "    tokens = []\n",
        "    segment_ids = []\n",
        "    \n",
        "    for token in tokens_a:\n",
        "        tokens.append(token)\n",
        "        segment_ids.append(SEG_ID_A)\n",
        "        \n",
        "    # Add <sep> token \n",
        "    tokens.append(SEP_ID)\n",
        "    segment_ids.append(SEG_ID_A)\n",
        "    \n",
        "    \n",
        "    # Add <cls> token\n",
        "    tokens.append(CLS_ID)\n",
        "    segment_ids.append(SEG_ID_CLS)\n",
        "    \n",
        "    input_ids = tokens\n",
        "    \n",
        "    # The mask has 0 for real tokens and 1 for padding tokens. Only real\n",
        "    # tokens are attended to.\n",
        "    input_mask = [0] * len(input_ids)\n",
        "\n",
        "    # Zero-pad up to the sequence length at fornt\n",
        "    if len(input_ids) < max_len:\n",
        "        delta_len = max_len - len(input_ids)\n",
        "        input_ids = [0] * delta_len + input_ids\n",
        "        input_mask = [1] * delta_len + input_mask\n",
        "        segment_ids = [SEG_ID_PAD] * delta_len + segment_ids\n",
        "\n",
        "    assert len(input_ids) == max_len\n",
        "    assert len(input_mask) == max_len\n",
        "    assert len(segment_ids) == max_len\n",
        "    \n",
        "\n",
        "    \n",
        "    \n",
        "        \n",
        "    print(\"sentence: %s\"%(sentence))\n",
        "    print(\"input_ids:%s\"%(input_ids))\n",
        "    print(\"attention_masks:%s\"%(input_mask))\n",
        "    print(\"segment_ids:%s\"%(segment_ids))\n",
        "    print(\"\\n\")\n",
        "    \n",
        "    return input_ids,input_mask,segment_ids,tag"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P9rjV5Fq43rM",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 145
        },
        "outputId": "85f7c275-6d90-4957-f193-ae6bb995c403"
      },
      "source": [
        "input_ids,input_masks,segment_ids,tag = encodeSentence('The food is so delicious',1)"
      ],
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sentence: The food is so delicious\n",
            "input_ids:[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 32, 626, 27, 102, 10182, 4, 3]\n",
            "attention_masks:[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]\n",
            "segment_ids:[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 0, 0, 0, 0, 0, 0, 2]\n",
            "\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iXpNKkbQ96EK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "test_inputs = torch.tensor(input_ids)\n",
        "\n",
        "test_tags = torch.tensor(tag)\n",
        "\n",
        "test_masks = torch.tensor(input_masks)\n",
        "\n",
        "test_segs = torch.tensor(segment_ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-SIVobEBWXt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_inputs = test_inputs.unsqueeze(0)\n",
        "test_tags = test_tags.unsqueeze(0)\n",
        "test_masks = test_masks.unsqueeze(0)\n",
        "test_segs = test_segs.unsqueeze(0)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y7NVWoAeBs4U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_data = TensorDataset(test_inputs, test_masks,test_segs, test_tags)\n",
        "test_sampler = SequentialSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_num)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ESTzkw6r9cti",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1699177f-563d-48c8-93cc-11a557ae47c4"
      },
      "source": [
        "for step, batch in enumerate(test_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_segs,b_labels = batch\n",
        "    \n",
        "    \n",
        "    b_segs = b_segs.squeeze(0)\n",
        "    outputs = model(input_ids =b_input_ids,token_type_ids=b_segs, input_mask = b_input_mask,labels=b_labels)\n",
        "    tmp_eval_loss, logits = outputs[:2]\n",
        "    \n",
        "    # Get textclassification predict result\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    tmp_eval_accuracy = accuracy(logits, label_ids)\n",
        "    print(tmp_eval_accuracy)"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}